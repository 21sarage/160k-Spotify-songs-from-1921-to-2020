# 160k-Spotify-songs-from-1921-to-2020

We used the _songsAnalysis.ipynb_ Jupyter Notebook as an example of how to implement a Data Science pipeline, through multiple stages:
- data collection
- data cleanup
- data visualization and statistical analysis
- statistical test (t-test)
- clustering (using the k-means algorithm)
- use of a predictive method (Linear Regression and Logistic Regression)

We focused on analyzing and predicting the popularity of the songs in the dataset (imported by [Kaggle](https://www.kaggle.com/datasets/fcpercival/160k-spotify-songs-sorted?select=data.csv)), studying the musical features that compose each track.



### How to use the notebook:
1) Go to [Kaggle](https://www.kaggle.com/datasets/fcpercival/160k-spotify-songs-sorted?select=data.csv) and download the file _data.csv_;
2) Download the file _songsAnalysis.ipynb_ from this repository and put it in the same directory of _data.csv_
3) Open the terminal and launch the notebook writing on the command line "jupyter notebook" (make sure to have Anaconda downloaded into your computer)
4) You will now be able to move into your computer's directories through the new page that will open; go into the directory with your _data.csv_ and _songsAnalysis.ipynb_ files
5) Open _songsAnalysis.ipynb_ and run the notebook with the "Run" command (make sure to have downloaded the required libraries)
